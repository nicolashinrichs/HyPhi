{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Tutorial: Geometric Analysis of the Embodied Telepresence Connection (ETC)\n",
        "\n",
        "**Objective:** To quantify the \"shape\" of inter-brain synchronization during pseudo-haptic interactions using Forman-Ricci Curvature (FRC) and Network Entropy (RNE).\n",
        "\n",
        "**Prerequisites:**\n",
        "\n",
        "* **Python 3.8+**\n",
        "\n",
        "* **Libraries:** `numpy`, `pandas`, `scipy`, `networkx`, `matplotlib`, `statsmodels`\n",
        "\n",
        "* **Data:** \\* Preprocessed fNIRS time-series (LIONirs output with `NaNs`)\n",
        "\n",
        "  * VR Kinematic logs (Head rotation, Hand displacement)\n",
        "\n",
        "  * ECG logs (Sec-by-sec PNS/Stress index)\n",
        "\n",
        "## Part 1: Dual-fNIRS Preprocessing (The LIONirs Handler)\n",
        "\n",
        "The LIONirs pipeline replaces motion artifacts with `NaNs`. For geometric analysis, we need continuous phase data. We must impute short gaps while respecting the \"Invalid\" status of long gaps.\n",
        "\n",
        "### 1.1 Dyadic Loading & Imputation Strategy\n",
        "\n",
        "We process both subjects simultaneously to ensure time-series lengths match exactly before any correlation is calculated.\n",
        "\n",
        "```python\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.interpolate import CubicSpline\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def rigorous_imputation(series, sampling_rate=10, max_gap_sec=2.0):\n",
        "    \"\"\"\n",
        "    Interpolates NaN gaps < 2s using Cubic Spline.\n",
        "    Returns: cleaned_series, valid_mask (False if gap > 2s)\n",
        "    \"\"\"\n",
        "    ts = series.copy()\n",
        "    max_gap_samples = int(max_gap_sec * sampling_rate)\n",
        "    is_nan = np.isnan(ts)\n",
        "\n",
        "    # Group consecutive NaNs\n",
        "    groups = is_nan.astype(int).groupby(is_nan.astype(int).diff().ne(0).cumsum()).cumsum()\n",
        "    valid_mask = np.ones(len(ts), dtype=bool)\n",
        "\n",
        "    for group_id, group in groups.groupby(groups):\n",
        "        if is_nan.iloc[group.index[0]]: # Found a NaN block\n",
        "            if len(group) <= max_gap_samples:\n",
        "                # Interpolate\n",
        "                start, end = group.index[0] - 1, group.index[-1] + 1\n",
        "                if start >= 0 and end < len(ts):\n",
        "                    x = [start, end]\n",
        "                    y = [ts.iloc[start], ts.iloc[end]]\n",
        "                    cs = CubicSpline(x, y)\n",
        "                    ts.iloc[group.index] = cs(group.index)\n",
        "            else:\n",
        "                # Mark invalid\n",
        "                valid_mask[group.index] = False\n",
        "\n",
        "    return ts, valid_mask\n",
        "\n",
        "def process_dyad_fnirs(df_s1, df_s2, channels):\n",
        "    \"\"\"\n",
        "    Applies imputation to paired fNIRS data.\n",
        "    \"\"\"\n",
        "    dyad_data = {}\n",
        "    validity_masks = []\n",
        "\n",
        "    for ch in channels:\n",
        "        # Subject 1\n",
        "        s1_clean, m1 = rigorous_imputation(df_s1[ch])\n",
        "        # Subject 2\n",
        "        s2_clean, m2 = rigorous_imputation(df_s2[ch])\n",
        "\n",
        "        dyad_data[f\"S1_{ch}\"] = zscore(s1_clean, nan_policy='omit')\n",
        "        dyad_data[f\"S2_{ch}\"] = zscore(s2_clean, nan_policy='omit')\n",
        "\n",
        "        # Global validity: If either S1 or S2 is invalid, the pair is invalid\n",
        "        validity_masks.append(m1 & m2)\n",
        "\n",
        "    # Combine masks: strict intersection (data must be valid in ALL channels to compute topology)\n",
        "    global_mask = np.logical_and.reduce(validity_masks)\n",
        "\n",
        "    return pd.DataFrame(dyad_data), global_mask"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "tmr4opWmH6LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: VR Kinematics Processing\n",
        "\n",
        "**Challenge:** VR data often logs at variable frame rates (e.g., 90Hz) or simply \"on event\". We need to resample this to match the fNIRS sampling rate (approx 10Hz) and calculate \"Motion Energy\" to regress out of the neural signal.\n",
        "\n",
        "**Data Source:** `Kinematic data structure-2.pdf` (Head Rotation X, Y, Z).\n",
        "\n",
        "### 2.1 Resampling & Motion Energy Calculation"
      ],
      "metadata": {
        "id": "TTj4vNohH6LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_kinematics(vr_file_path, target_timestamps):\n",
        "    \"\"\"\n",
        "    Loads VR logs, extracts head rotation, and resamples to fNIRS timestamps.\n",
        "    \"\"\"\n",
        "    df_vr = pd.read_csv(vr_file_path) # Assuming CSV export\n",
        "\n",
        "    # 1. Create a datetime index or relative time index for VR\n",
        "    # conversion of 'Time' column to seconds if needed\n",
        "\n",
        "    # 2. Extract Head Rotation columns\n",
        "    # Adjust column names based on actual file header\n",
        "    cols_of_interest = [\n",
        "        'P1 head rotation x', 'P1 head rotation y', 'P1 head rotation z',\n",
        "        'P2 head rotation x', 'P2 head rotation y', 'P2 head rotation z',\n",
        "        'P1 hand displacement', 'P2 hand displacement'\n",
        "    ]\n",
        "\n",
        "    # 3. Resample to fNIRS target_timestamps (linear interpolation)\n",
        "    vr_resampled = pd.DataFrame(index=target_timestamps)\n",
        "\n",
        "    for col in cols_of_interest:\n",
        "        # Interpolate VR data onto fNIRS timepoints\n",
        "        vr_resampled[col] = np.interp(\n",
        "            target_timestamps,\n",
        "            df_vr['Time'], # VR time column\n",
        "            df_vr[col]\n",
        "        )\n",
        "\n",
        "    # 4. Calculate Composite Motion Energy (Derivative)\n",
        "    # We want the change in rotation (velocity) as the artifact source\n",
        "    for p in ['P1', 'P2']:\n",
        "        rot_cols = [f'{p} head rotation {ax}' for ax in ['x', 'y', 'z']]\n",
        "        # Euclidean norm of the derivative\n",
        "        diffs = vr_resampled[rot_cols].diff().fillna(0)\n",
        "        vr_resampled[f'{p}_Head_Motion_Energy'] = np.sqrt(\n",
        "            diffs.iloc[:,0]**2 + diffs.iloc[:,1]**2 + diffs.iloc[:,2]**2\n",
        "        )\n",
        "\n",
        "    return vr_resampled"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "hgFyzPW1H6LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Neural Regression\n",
        "\n",
        "We remove variance in HbO caused purely by head movement."
      ],
      "metadata": {
        "id": "GePczWLaH6LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "def regress_out_motion(neural_signal, motion_regressors):\n",
        "    \"\"\"\n",
        "    neural_signal: 1D array (fNIRS channel)\n",
        "    motion_regressors: 2D array (Head Motion Energy X, Y, Z)\n",
        "    \"\"\"\n",
        "    X = sm.add_constant(motion_regressors)\n",
        "    model = sm.OLS(neural_signal, X, missing='drop').fit()\n",
        "    return model.resid # The \"cleaned\" neural signal"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "2Sx0gMwyH6LW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: ECG Data Processing\n",
        "\n",
        "**Challenge:** ECG data (`ECG data structure.pdf`) is \"sec-by-sec\". If fNIRS is 10Hz, we have a mismatch.\n",
        "**Goal:** Align PNS Index (Vagal Tone) to use as a predictor for Geometric Entropy.\n",
        "\n",
        "### 3.1 Alignment Strategy\n",
        "\n",
        "Since `PNS Index` changes slowly (autonomic state), we step-interpolate (forward fill) it to match the fNIRS 10Hz resolution."
      ],
      "metadata": {
        "id": "sVEMRNVJH6LW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_ecg(ecg_file_path, target_timestamps):\n",
        "    df_ecg = pd.read_csv(ecg_file_path)\n",
        "\n",
        "    # Columns from PDF\n",
        "    target_cols = ['PNS index', 'Stress index', 'Mean HR']\n",
        "\n",
        "    ecg_aligned = pd.DataFrame(index=target_timestamps)\n",
        "\n",
        "    for col in target_cols:\n",
        "        # Use 'nearest' or 'previous' interpolation for physiological states\n",
        "        # fNIRS time 10.1s should take ECG value from 10.0s\n",
        "        f = CubicSpline(df_ecg['Time'], df_ecg[col])\n",
        "        ecg_aligned[col] = f(target_timestamps)\n",
        "\n",
        "    return ecg_aligned"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "I9nh3vCHH6LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Constructing Annotated Weighted Connectivity Matrices\n",
        "\n",
        "This step fuses the neural, physiological, and behavioral data. We iterate through time windows, creating a snapshot of the brain network (Weighted Matrix) and tagging it with the concurrent ECG and VR states (Annotations)."
      ],
      "metadata": {
        "id": "xw-KxZPDH6LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_condition_info(timestamp):\n",
        "    \"\"\"\n",
        "    Placeholder: Map a timestamp to your experimental block (Touch, ISI, Free).\n",
        "    You should implement the specific logic from your 'ETC_dual person_short.pptx' timings here.\n",
        "    \"\"\"\n",
        "    # Example logic:\n",
        "    # if 0 < timestamp < 60: return \"Pseudo\", \"Free\"\n",
        "    # if 60 < timestamp < 78: return \"Pseudo\", \"ISI\"\n",
        "    return \"Unknown\", \"Unknown\"\n",
        "\n",
        "def build_annotated_graphs(fnirs_dyad, vr_data, ecg_data, window_size=150, step_size=10):\n",
        "    \"\"\"\n",
        "    Generates a sequence of weighted connectivity matrices annotated with physiological and behavioral states.\n",
        "\n",
        "    Args:\n",
        "        fnirs_dyad (pd.DataFrame): Cleaned, z-scored fNIRS data (columns: S1_Ch1, ..., S2_Ch1...)\n",
        "        vr_data (pd.DataFrame): Resampled VR kinematics (Head motion, Hand displacement).\n",
        "        ecg_data (pd.DataFrame): Aligned ECG metrics (PNS index).\n",
        "        window_size (int): Samples per window (e.g., 15s * 10Hz = 150).\n",
        "        step_size (int): Samples to shift (e.g., 1s * 10Hz = 10).\n",
        "\n",
        "    Returns:\n",
        "        list: A list of dictionary objects, where each object represents one time window.\n",
        "    \"\"\"\n",
        "    annotated_graphs = []\n",
        "\n",
        "    # 1. Define loop parameters\n",
        "    num_samples = len(fnirs_dyad)\n",
        "\n",
        "    # 2. Sliding Window Loop\n",
        "    for start_idx in range(0, num_samples - window_size, step_size):\n",
        "        end_idx = start_idx + window_size\n",
        "\n",
        "        # --- A. Slice the Data Streams ---\n",
        "        window_fnirs = fnirs_dyad.iloc[start_idx:end_idx]\n",
        "        window_vr = vr_data.iloc[start_idx:end_idx]\n",
        "        window_ecg = ecg_data.iloc[start_idx:end_idx]\n",
        "\n",
        "        # --- B. Quality Check ---\n",
        "        # If too many NaNs remain (from valid_mask in Part 1), skip this window\n",
        "        if window_fnirs.isnull().mean().mean() > 0.1:\n",
        "            continue\n",
        "\n",
        "        # --- C. Build Connectivity Matrix (The \"Network\") ---\n",
        "        # Weighted Pearson Correlation: W_ij = |r_ij|\n",
        "        corr_matrix = window_fnirs.corr(method='pearson')\n",
        "\n",
        "        # Convert to absolute weights (standard for functional connectivity)\n",
        "        weight_matrix = corr_matrix.abs().values\n",
        "\n",
        "        # Zero out self-loops (diagonal)\n",
        "        np.fill_diagonal(weight_matrix, 0)\n",
        "\n",
        "        # --- D. Aggregate Annotations (The \"Context\") ---\n",
        "        # Calculate the mean state of the participants *during this specific network snapshot*\n",
        "\n",
        "        # Get experimental phase info\n",
        "        current_time = window_fnirs.index[0]\n",
        "        condition, phase = get_condition_info(current_time)\n",
        "\n",
        "        annotation = {\n",
        "            'timestamp_start': current_time,\n",
        "            'timestamp_end': window_fnirs.index[-1],\n",
        "            'condition': condition,\n",
        "            'phase': phase,\n",
        "\n",
        "            # Physiological Annotations\n",
        "            'mean_PNS': window_ecg['PNS index'].mean(),\n",
        "            'mean_Stress': window_ecg['Stress index'].mean(),\n",
        "\n",
        "            # Behavioral Annotations (Force/Embodiment proxy)\n",
        "            'mean_hand_displacement': window_vr[[c for c in window_vr.columns if 'hand displacement' in c]].mean().mean(),\n",
        "\n",
        "            # Control Variable (Motion Artifact proxy)\n",
        "            'mean_head_motion': window_vr[[c for c in window_vr.columns if 'Motion_Energy' in c]].mean().mean()\n",
        "        }\n",
        "\n",
        "        # --- E. Store ---\n",
        "        annotated_graphs.append({\n",
        "            'matrix': weight_matrix,   # This goes to the Geometric Toolkit\n",
        "            'metadata': annotation     # This goes to the Statistical Model\n",
        "        })\n",
        "\n",
        "    return annotated_graphs"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "8ru33YHAH6LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Geometric Computation (The HyPhi Pipeline)\n",
        "\n",
        "With our list of `annotated_graphs`, we can now compute the topology.\n",
        "\n",
        "### 5.1 Augmented Forman-Ricci Curvature (AFRC)"
      ],
      "metadata": {
        "id": "5CDwEdm5H6LX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "\n",
        "def compute_afrc(adj_matrix):\n",
        "    G = nx.from_numpy_array(adj_matrix)\n",
        "    curvature_dict = {}\n",
        "\n",
        "    for u, v in G.edges():\n",
        "        w_uv = G[u][v]['weight']\n",
        "        if w_uv == 0: continue\n",
        "\n",
        "        # Node weights ~ sum of neighbors\n",
        "        s_u = sum([G[u][n]['weight'] for n in G[u] if n != v])\n",
        "        s_v = sum([G[v][n]['weight'] for n in G[v] if n != u])\n",
        "\n",
        "        # Triangles (Cycles)\n",
        "        triangles = sorted(list(nx.common_neighbors(G, u, v)))\n",
        "        triangle_sum = 0\n",
        "        for t in triangles:\n",
        "            w_ut = G[u][t]['weight']\n",
        "            w_vt = G[v][t]['weight']\n",
        "            triangle_sum += max(w_ut, w_vt)\n",
        "\n",
        "        # AFRC Formula Approximation\n",
        "        # F(e) ~ 4 - degrees + triangles\n",
        "        frc = w_uv * (2 - (s_u/np.sqrt(w_uv) + s_v/np.sqrt(w_uv)) + triangle_sum)\n",
        "        curvature_dict[(u,v)] = frc\n",
        "\n",
        "    return list(curvature_dict.values())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "tDcOvVQaH6LX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2 Ricci Network Entropy (RNE) & Final Integration\n",
        "\n",
        "We iterate through the `annotated_graphs` list, compute the RNE for each matrix, and flatten the result into a DataFrame for statistics."
      ],
      "metadata": {
        "id": "SuOFcKRIH6LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import entropy\n",
        "\n",
        "def compute_rne(curvature_values, bins=20):\n",
        "    counts, _ = np.histogram(curvature_values, bins=bins, density=True)\n",
        "    return entropy(counts + 1e-10)\n",
        "\n",
        "def run_geometric_pipeline(annotated_graphs):\n",
        "    results = []\n",
        "\n",
        "    for item in annotated_graphs:\n",
        "        matrix = item['matrix']\n",
        "        meta = item['metadata']\n",
        "\n",
        "        # 1. Compute Curvature\n",
        "        curvatures = compute_afrc(matrix)\n",
        "\n",
        "        # 2. Compute Entropy\n",
        "        rne = compute_rne(curvatures)\n",
        "\n",
        "        # 3. Combine for export\n",
        "        row = meta.copy()\n",
        "        row['RNE'] = rne\n",
        "        row['Mean_Curvature'] = np.mean(curvatures)\n",
        "        results.append(row)\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Usage:\n",
        "# final_df = run_geometric_pipeline(annotated_graphs)\n",
        "# final_df.to_csv(\"ETC_Geometric_Analysis_Results.csv\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "IqGWCTcmH6LY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6: Statistical Evaluation\n",
        "\n",
        "**Final Model Structure:**\n",
        "\n",
        "We construct a master DataFrame where every row is one time-window (t).\n",
        "\n",
        "| **Time** | **Condition** | **Phase** | **RNE (Outcome)** | **PNS_Index** | **Hand_Disp** |\n",
        "| 15.0 | Pseudo | Touch | 2.45 | \\-0.5 | 0.02 |\n",
        "| 16.0 | Pseudo | Touch | 2.89 | \\-0.4 | 0.15 |\n",
        "\n",
        "**Hypothesis Testing (LMM):**\n",
        "`RNE ~ Condition * Phase + Motion_Energy + PNS_Index + (1 | DyadID)`\n",
        "\n",
        "* **Higher RNE** in Pseudo-Touch implies the brain is geometrically reorganizing to solve the sensory conflict.\n",
        "\n",
        "* **PNS Index** interaction: Does high vagal tone (safety) allow for higher geometric flexibility (higher RNE)?\n",
        "```\n",
        "  ```"
      ],
      "metadata": {
        "id": "_vn9EyA3H6LY"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}